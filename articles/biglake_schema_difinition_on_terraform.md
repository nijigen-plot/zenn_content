---
title: "Listå‹ã§èº“ã‹ãªã„ BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã®JSONã‚¹ã‚­ãƒ¼ãƒå®šç¾©"
emoji: "ğŸ™"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["BigQuery", "Terraform", "Parquet"]
published: true
---

## å†…å®¹

BigQueryã®BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã‚’Terraform [google_bigquery_schema](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_table)ã§ä½œæˆã™ã‚‹å ´åˆã€
`external_data_configuration`å¼•æ•°ã«æƒ…å ±ã‚’å…¥ã‚Œã€`schema`å¼•æ•°ã«ã‚¹ã‚­ãƒ¼ãƒã®æƒ…å ±ã‚’jsonã§æ›¸ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
ãã®éš›ã€Listã‚„Mapå‹ã®ã‚ˆã†ãªè¤‡æ•°ã®è¦ç´ ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã€ã©ã®ã‚ˆã†ã«jsonã§å‹ã‚’å®šç¾©ã™ã‚Œã°ã„ã„ã®ã‹ã§å¤šå°‘æ™‚é–“ã‚’æ¶ˆè²»ã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‚Šã¾ã—ãŸã€‚

æœ¬è¨˜äº‹ã§ã¯ã€Œã‚¹ãƒ ãƒ¼ã‚ºãªå®šç¾©æ–¹æ³•ã€ã¨ã€ã€Œãªãœãã‚Œã§ã†ã¾ãã„ãã®ã‹ã€ã‚’æ›¸ã„ã¦ã„ãã¾ã™ã€‚

## ã‚¹ãƒ ãƒ¼ã‚ºãªå®šç¾©æ–¹æ³•

ã‚¹ãƒ ãƒ¼ã‚ºã«å®šç¾©ã‚’è¡Œã†ãŠã™ã™ã‚ã®æ–¹æ³•ã¯[duckDB](https://duckdb.org/)ã®[Auto Detection](https://duckdb.org/docs/stable/data/csv/auto_detection)ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å–ã‚Šâ†’[parquetãƒ•ã‚¡ã‚¤ãƒ«ã§æ›¸ãå‡ºã—](https://duckdb.org/docs/stable/sql/statements/copy#copy--to)ã€[parquet_schema()](https://duckdb.org/docs/stable/data/parquet/metadata#parquet-schema)ã‚’ç”¨ã„ã¦parquet metadataã‚’è¡¨ç¤ºã—ã€ãã‚Œã‚’ã‚‚ã¨ã«jsonã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆã™ã‚‹ ã§ã™ã€‚

```mermaid
flowchart TD
  %% DuckDB â†’ Parquet metadata â†’ BigQuery/BigLake JSON schema â†’ Terraform

  A["å…¥åŠ›ãƒ‡ãƒ¼ã‚¿<br/>(CSV / JSONL / JSON)"] --> B["DuckDBã§parquetã«å¤‰æ›"]
  B --> C["parquet_schema()ã§schema ã‚’ç¢ºèª"]
  C --> D["BigQuery ç”¨ JSON schema ã‚’ä½œæˆ"]
  D --> E["Terraformã§BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"]

```


## BigLakeã§ã®parquetèª­ã¿å–ã‚Šæ™‚List Logical Typeä»•æ§˜

ã€Œãªãœã“ã‚Œã§ã†ã¾ãã„ãã®ã‹ã€ã¯BigQuery,parquet,DuckDBã®ä»•æ§˜ã‚’èª­ã‚€ã¨ã‚ã‹ã‚Šã¾ã™ã€‚

https://docs.cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet#list_logical_type

> BigQuery checks whether the LIST node is in the standard form or in one of the forms described by the backward-compatibility rules:

```
// standard form
<optional | required> group <name> (LIST) {
  repeated group list {
    <optional | required> <element-type> element;
  }
}
```

BigQueryã®Load Dataã§Listè«–ç†å‹ã‚’èª­ã‚€å ´åˆã¯parquet-formatã®[standard form](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#lists)ã«å‰‡ã‚Œã°ã‚ˆã•ãã†ã§ã™ã€‚

```example
// List<String> (list non-null, elements nullable)
required group my_list (LIST) {
  repeated group list {
    optional binary element (STRING);
  }
}

// List<String> (list nullable, elements non-null)
optional group my_list (LIST) {
  repeated group list {
    required binary element (STRING);
  }
}
```

æœ¬è¨˜äº‹ã§ã¯çœç•¥ã—ã¾ã™ãŒã€[backward-compatibility rules](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#backward-compatibility-rules)ã«å¾“ã†å½¢ã§ã‚‚è‰¯ã„ã§ã™ã€‚


### BigQuery ãƒã‚¹ãƒˆã‚„ç¹°ã‚Šè¿”ã—ã®åˆ—å®šç¾©

ã¾ãŸã€JSONã§å®šç¾©ã™ã‚‹éš›ã®type(å‹)ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã€‚

https://docs.cloud.google.com/bigquery/docs/nested-repeated?utm_source=chatgpt.com

> To create a column with nested data, set the data type of the column to RECORD in the schema. A RECORD can be accessed as a STRUCT type in GoogleSQL. A STRUCT is a container of ordered fields.

> To create a column with repeated data, set the mode of the column to REPEATED in the schema. A repeated field can be accessed as an ARRAY type in GoogleSQL.

> A RECORD column can have REPEATED mode, which is represented as an array of STRUCT types. Also, a field within a record can be repeated, which is represented as a STRUCT that contains an ARRAY. An array cannot contain another array directly. For more information, see Declaring an ARRAY type.

- BigQueryã®`RECORD`å‹ã¯GoogleSQLã®`STRUCT`å‹ã«å¯¾å¿œã™ã‚‹
- `REPEATED`å‹ã¯GoogleSQLã®`ARRAY`å‹ã«å¯¾å¿œã™ã‚‹
- `RECORD`å‹ã®ã‚«ãƒ©ãƒ ã¯`REPEATED`ã‚’æŒã¤ã“ã¨ãŒã§ãã€`ARRAY<STRUCT<...>>`ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹
- `ARRAY`ã®ä¸­ã«`ARRAY`ã‚’å…¥ã‚Œã‚‹ã“ã¨ã¯ã§ããªã„


## duckDBã§ã®parquet_schemaä»•æ§˜

https://duckdb.org/docs/stable/data/parquet/metadata#parquet-schema

> Note that this is the schema as it is contained within the metadata of the Parquet file. If you want to figure out the column names and types contained within a Parquet file it is easier to use DESCRIBE.


`parquet_schema()`ã§ã¯parquetãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¦ã„ã‚‹æ—¨ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚

DESCRIBEã§ã¯duckDBã®è§£é‡ˆãƒ™ãƒ¼ã‚¹ã®è¡¨ç¤ºã«ãªã‚‹ãŸã‚`parquet_schema()`ã‚’ä½¿ã†ã®ãŒé©åˆ‡ãã†ã§ã™ã€‚


## å®Ÿéš›ã«è©¦ã—ã¦ã¿ã‚‹

ã¨ã„ã†ã“ã¨ã§ã€ã‚¹ãƒ ãƒ¼ã‚ºãªå®šç¾©æ–¹æ³•ã«ã¤ã„ã¦è©¦ã—ã¦ã¿ã¾ã™ã€‚

ç’°å¢ƒã¯

- duckdb v1.4.2
- terraform v1.12.2
- terraform hashicorp/google v.5.45.2


ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå½¢ã§ã™ã€‚

```json:test.jsonl
{"id":1,"nums":[1,2,null],"events":[{"ts":"2025-12-01T00:00:00Z","kind":"a"},{"ts":null,"kind":"b"}],"tags":[{"key":"env","value":"prod"},{"key":"team","value":null}]}
{"id":2,"nums":[],"events":null,"tags":[{"key":"env","value":"dev"}]}
{"id":3,"nums":null,"events":[],"tags":null}
```



ã¾ãšã¯jsonl to parquetã®.sqlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œã‚Šå¤‰æ›ã—ã¾ã™ã€‚

```sql:test.jsonl.transform.sql
COPY (
    SELECT * FROM read_json_auto('test.jsonl')
) TO 'test.parquet' (FORMAT PARQUET);
```


```duckdb
D .read test.jsonl.transform.sql
```


ç”Ÿæˆã•ã‚ŒãŸparquetãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰parquet schemaæƒ…å ±ã‚’è¦‹ã¦ã¿ã¾ã™ã€‚


```duckdb
D select * from parquet_schema('test.parquet');
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  file_name   â”‚     name      â”‚ â€¦ â”‚     logical_type     â”‚ duckdb_type â”‚
â”‚   varchar    â”‚    varchar    â”‚   â”‚       varchar        â”‚   varchar   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ test.parquet â”‚ duckdb_schema â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ id            â”‚ â€¦ â”‚ NULL                 â”‚ BIGINT      â”‚
â”‚ test.parquet â”‚ nums          â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ list          â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ element       â”‚ â€¦ â”‚ NULL                 â”‚ BIGINT      â”‚
â”‚ test.parquet â”‚ events        â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ list          â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ element       â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ ts            â”‚ â€¦ â”‚ TimestampType(isAdâ€¦  â”‚ TIMESTAMP   â”‚
â”‚ test.parquet â”‚ kind          â”‚ â€¦ â”‚ NULL                 â”‚ VARCHAR     â”‚
â”‚ test.parquet â”‚ tags          â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ list          â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ element       â”‚ â€¦ â”‚ NULL                 â”‚ NULL        â”‚
â”‚ test.parquet â”‚ key           â”‚ â€¦ â”‚ NULL                 â”‚ VARCHAR     â”‚
â”‚ test.parquet â”‚ value         â”‚ â€¦ â”‚ NULL                 â”‚ VARCHAR     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 15 rows                                          12 columns (4 shown) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


`DESCIBE`ã®å ´åˆã“ã®ã‚ˆã†ãªè¡¨ç¤ºã«ãªã‚Šã¾ã™ã€‚


```duckdb
D DESCRIBE SELECT * FROM 'test.parquet';
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ column_name â”‚       column_type       â”‚  null   â”‚   key   â”‚ default â”‚  extra  â”‚
â”‚   varchar   â”‚         varchar         â”‚ varchar â”‚ varchar â”‚ varchar â”‚ varchar â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id          â”‚ BIGINT                  â”‚ YES     â”‚ NULL    â”‚ NULL    â”‚ NULL    â”‚
â”‚ nums        â”‚ BIGINT[]                â”‚ YES     â”‚ NULL    â”‚ NULL    â”‚ NULL    â”‚
â”‚ events      â”‚ STRUCT(ts TIMESTAMP, â€¦  â”‚ YES     â”‚ NULL    â”‚ NULL    â”‚ NULL    â”‚
â”‚ tags        â”‚ STRUCT("key" VARCHAR,â€¦  â”‚ YES     â”‚ NULL    â”‚ NULL    â”‚ NULL    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


terraformã‹ã‚‰BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œã‚‹ãŸã‚ã®jsonã‚’ä½œæˆã—ã€BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œã‚Šã¾ã™ã€‚

duckDBã®parquet_schemaã®nameã‚’è¦‹ã¤ã¤æ›¸ã„ã¦ã„ãã¾ã™ã€‚

```json:schema.json( #ä»¥é™ã¯ã‚³ãƒ¡ãƒ³ãƒˆ)
[
    {
        "name": "id",
        "type": "INT64", # idã¯INTã®1è¦ç´ 
        "mode": "NULLABLE"
    },
    {
        "name": "nums",
        "type": "RECORD",
        "mode": "NULLABLE", # numsã¯nullã‚‚å­˜åœ¨ã™ã‚‹æ•°å­—é…åˆ—
        "fields": [
            {
                "name": "list",
                "type": "RECORD",
                "mode": "REPEATED", # RECORDå‹ã¯REPEATEDå‹ã‚’æŒã¦ã‚‹ã€‚DuckDBã§ã¿ã‚‹ã¨ã“ã“ãŒlistãªã®ã§name = listã¨ã™ã‚‹
                "fields": [
                    {
                        "name" : "element", # DuckDBã§è¦‹ã‚‹ã¨elementãªã®ã§ãã®ã‚ˆã†ã«å®šç¾©
                        "type": "INT64",
                        "mode": "NULLABLE"
                    }
                ]
            }
        ]
    },
    {
        "name": "events", # numsã¨æµã‚Œã¯å¤§ä½“ä¸€ç·’ã€‚
        "type": "RECORD",
        "mode": "NULLABLE",
        "fields": [
            {
                "name": "list",
                "type": "RECORD",
                "mode": "REPEATED",
                "fields" : [
                    {
                        "name": "element",
                        "type": "RECORD",
                        "mode": "NULLABLE",
                        "fields": [ # ã“ã“ãŒtsã¨kindã§åˆ†ã‹ã‚Œã¦å‹å®šç¾©
                            {
                                "name": "ts",
                                "type": "TIMESTAMP",
                                "mode": "NULLABLE"
                            },
                            {
                                "name": "kind",
                                "type": "STRING",
                                "mode": "NULLABLE"
                            }
                        ]
                    }
                ]
            }
        ]
    },
    {
        "name": "tags", # eventsã¨å¤§ä½“ä¸€ç·’
        "type": "RECORD",
        "mode": "NULLABLE",
        "fields": [
            {
                "name": "list",
                "type": "RECORD",
                "mode": "REPEATED",
                "fields" : [
                    {
                        "name": "element",
                        "type": "RECORD",
                        "mode": "NULLABLE",
                        "fields": [
                            {
                                "name": "key",
                                "type": "STRING",
                                "mode": "NULLABLE"
                            },
                            {
                                "name": "value",
                                "type": "STRING",
                                "mode": "NULLABLE"
                            }
                        ]
                    }
                ]
            }
        ]
    }
]

```

ä½œæˆã—ãŸjsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã«ä½¿ã„ã€terraformã§BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œã‚Šã¾ã™ã€‚

```tf:main.tf
variable "project_id" {
  description = "GCP Project ID"
  type        = string
  default     = "xxxxxxxx"
}
variable "region" {
  description = "GCP Region"
  type        = string
  default     = "asia-northeast1"
}
variable "dataset_id" {
  description = "BigQuery Dataset ID"
  type        = string
  default     = "biglake_test_dataset"
}
variable "table_id" {
  description = "BigQuery Table ID"
  type        = string
  default     = "external_table_test"
}
variable "gcs_bucket" {
  description = "GCS Bucket for BigLake data"
  type        = string
  default     = "yyyyyyyy"
}
variable "gcs_path" {
  description = "GCS Path for BigLake data"
  type        = string
  default     = "biglake/test_data/*"
}
# BigQuery Dataset
resource "google_bigquery_dataset" "biglake_dataset" {
  dataset_id  = var.dataset_id
  location    = var.region
  description = "Dataset for BigLake external table testing"
}
# BigLakeç”¨ã®Cloud Resource Connection
resource "google_bigquery_connection" "biglake" {
  connection_id = "biglake-test-connection"
  location      = var.region
  friendly_name = "BigLake Test Connection"
  description   = "Connection for BigLake external tables to access Cloud Storage"
  cloud_resource {}
}
# BigLake External Table
resource "google_bigquery_table" "external" {
  dataset_id  = google_bigquery_dataset.biglake_dataset.dataset_id
  table_id    = var.table_id
  description = "BigLake external table for testing"
  # ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
  schema              = file("${path.module}/schema.json")
  deletion_protection = false
  external_data_configuration {
    autodetect    = false
    source_format = "PARQUET"
    source_uris = [
      "gs://${var.gcs_bucket}/${var.gcs_path}"
    ]
    connection_id       = google_bigquery_connection.biglake.id
    metadata_cache_mode = "AUTOMATIC"
  }
  max_staleness = "0-0 0 10:0:0" # 10æ™‚é–“
  depends_on = [
    google_bigquery_dataset.biglake_dataset,
    google_bigquery_connection.biglake
  ]
}
# BigLake Connectionç”¨ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«Cloud Storageã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã‚’ä»˜ä¸
resource "google_storage_bucket_iam_member" "biglake_storage" {
  bucket = var.gcs_bucket
  role   = "roles/storage.objectViewer"
  member = "serviceAccount:${google_bigquery_connection.biglake.cloud_resource[0].service_account_id}"
}

```

```tf:provider.tf
terraform {
  required_version = ">= 1.0.0"

  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
}
```

```bash
$ terraform init
$ terraform plan
$ terraform apply
...
Apply complete! Resources: 4 added, 0 changed, 0 destroyed.
```


æŒ‡å®šã®GCSã«test.parquetã‚’é…ç½®ã—ã€é©åˆ‡ã«èª­ã‚ã¦ã„ã‚‹ã‹ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚


![](/images/biglake_schema_difinition_on_terraform/2025-12-14215400.png)


![](/images/biglake_schema_difinition_on_terraform/2025-12-14215550.png)

ç„¡äº‹ã«èª­ã‚ã¦ã„ã¾ã™ã­ï¼ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã¯ç©ºé…åˆ—`[]`ã¨`null`ãŒã©ã¡ã‚‰ã‚‚ã‚ã‚Šã¾ã™ã®ã§ã€ãã®å ´åˆã¯æœ€å¤–å±¤å®šç¾©æ™‚ã«modeã‚’`NULLABLE`ã«ã™ã‚Œã°ã“ã®ã‚ˆã†ã«èª­ã‚ã¾ã™ã€‚

## ã¾ã¨ã‚

BigLakeãƒ†ãƒ¼ãƒ–ãƒ«ã§parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¾ã›ã‚‹éš›ã®å‹å®šç¾©ã¯[parquet-schema List Logical Type](https://github.com/apache/parquet-format/blob/master/LogicalTypes.md#lists)ã«å¾“ã£ã¦è§£é‡ˆã•ã‚Œã‚‹ã®ã§ã€ãã‚Œã«æº–ã˜ãŸjson schemaã‚’å®šç¾©ã™ã‚Œã°ã‚ˆã„


ã“ã“ã¾ã§èª­ã‚“ã§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚èª¤ã‚Šã‚„æ„è¦‹ãªã©ã‚ã‚Œã°ã‚³ãƒ¡ãƒ³ãƒˆã„ãŸã ã‘ã¾ã™ã¨å¬‰ã—ã„ã§ã™ã€‚
